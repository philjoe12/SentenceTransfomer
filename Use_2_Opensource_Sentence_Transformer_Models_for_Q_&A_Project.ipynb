{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMyJ+Gk7UsQ7AmgxB6jWhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/philjoe12/SentenceTransfomer/blob/main/Use_2_Opensource_Sentence_Transformer_Models_for_Q_%26A_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!install --upgrade pip"
      ],
      "metadata": {
        "id": "PR395hRljERt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install mesa-utils\n"
      ],
      "metadata": {
        "id": "3CCDmDYVkU_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install build-essential libpoppler-cpp-dev pkg-config python3-dev\n"
      ],
      "metadata": {
        "id": "boXEOxEHla6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "id": "KbO2YsAMjeP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools\n"
      ],
      "metadata": {
        "id": "5N5nOMWZlRVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "id": "2LUL7XzMiuMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libpoppler-cpp-dev\n",
        "!pip install pdftotext"
      ],
      "metadata": {
        "id": "QGKbUnmoiXD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Sentence transformers Model "
      ],
      "metadata": {
        "id": "y7nQ9piIMsom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "id": "5GoxbjLMlvOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Using the Sentence Transfomer Model***\n",
        "The line \"sentence_transformers import SentenceTransformer\" is importing a library called SentenceTransformers, which is not specifically based on BERT or BART architectures.\n",
        "\n",
        "SentenceTransformers is an open-source Python library developed by UKPLab that provides pre-trained models for generating dense vector representations of sentences or text snippets. \n",
        "\n",
        "These models are trained using various architectures, including BERT, RoBERTa, DistilBERT, and other transformer-based models."
      ],
      "metadata": {
        "id": "MMnxso4sM9D1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zvs48tURz5f"
      },
      "outputs": [],
      "source": [
        "import pdftotext\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Define file paths\n",
        "file_paths = ['/content/2023 State of Marketing Report.pdf', \n",
        "              '/content/Accenture-The-Future-Vision-of-Marketing-Operations.pdf', \n",
        "              '/content/DI_GMT-2023.pdf', \n",
        "              '/content/Influencer_Marketing_Benchmark_Report_2023.pdf',\n",
        "              '/content/marketing_predicts_for_2023_ebook.pdf',\n",
        "              '/content/salesforce-research-eighth-state-of-marketing.pdf']\n",
        "\n",
        "def get_most_similar_paragraph(question, embeddings_matrix, paragraphs):\n",
        "    question_embedding = model.encode([question])\n",
        "    similarity_scores = np.dot(embeddings_matrix, question_embedding[0].T)\n",
        "    most_similar_idx = np.argmax(similarity_scores)\n",
        "    return paragraphs[most_similar_idx]\n",
        "\n",
        "for file_path in file_paths:\n",
        "    # Extract text from the file and join into a single string\n",
        "    with open(file_path, 'rb') as f:\n",
        "        pdf = pdftotext.PDF(f)\n",
        "        text = '\\n\\n'.join(pdf)\n",
        "    # Preprocess the text by splitting it into paragraphs and removing any unnecessary characters\n",
        "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip() != '']\n",
        "\n",
        "    # Embed each paragraph and store the embeddings in a matrix\n",
        "    embeddings = model.encode(paragraphs)\n",
        "    embeddings_matrix = np.vstack(embeddings)\n",
        "\n",
        "    print(f\"Number of paragraphs: {len(paragraphs)}\")\n",
        "    print(f\"Shape of embeddings matrix: {embeddings_matrix.shape}\")\n",
        "\n",
        "    # Ask your question for each file\n",
        "    question = \"what are the top opportunities and solutions for advertisers\"\n",
        "    most_similar_paragraph = get_most_similar_paragraph(question, embeddings_matrix, paragraphs)\n",
        "    print(f\"For the file '{file_path}', the most similar paragraph to the question is: \\n{most_similar_paragraph}\\n\")\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdftotext sentence-transformers numpy\n"
      ],
      "metadata": {
        "id": "TrUSc42X5Hvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdftotext\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Initialize SentenceTransformer model\n",
        "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "# Define file paths\n",
        "file_paths = ['/content/2023 State of Marketing Report.pdf', \n",
        "              '/content/Accenture-The-Future-Vision-of-Marketing-Operations.pdf', \n",
        "              '/content/DI_GMT-2023.pdf', \n",
        "              '/content/Influencer_Marketing_Benchmark_Report_2023.pdf',\n",
        "              '/content/marketing_predicts_for_2023_ebook.pdf',\n",
        "              '/content/salesforce-research-eighth-state-of-marketing.pdf']\n",
        "\n",
        "def get_most_similar_paragraph(question, embeddings_matrix, paragraphs):\n",
        "    question_embedding = model.encode([question])\n",
        "    similarity_scores = np.dot(embeddings_matrix, question_embedding[0].T)\n",
        "    most_similar_idx = np.argmax(similarity_scores)\n",
        "    return paragraphs[most_similar_idx]\n",
        "\n",
        "for file_path in file_paths:\n",
        "    # Extract text from the file and join into a single string\n",
        "    with open(file_path, 'rb') as f:\n",
        "        pdf = pdftotext.PDF(f)\n",
        "        text = '\\n\\n'.join(pdf)\n",
        "\n",
        "    # Preprocess the text by splitting it into paragraphs and removing any unnecessary characters\n",
        "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip() != '']\n",
        "\n",
        "    # Embed each paragraph and store the embeddings in a matrix\n",
        "    embeddings = model.encode(paragraphs)\n",
        "    embeddings_matrix = np.vstack(embeddings)\n",
        "\n",
        "    print(f\"Number of paragraphs: {len(paragraphs)}\")\n",
        "    print(f\"Shape of embeddings matrix: {embeddings_matrix.shape}\")\n",
        "\n",
        "    # Ask your question for each file\n",
        "    question = \"what are the top trends for advertisers in 2023\"\n",
        "    most_similar_paragraph = get_most_similar_paragraph(question, embeddings_matrix, paragraphs)\n",
        "    print(f\"For the file '{file_path}', the most similar paragraph to the question is: \\n{most_similar_paragraph}\\n\")"
      ],
      "metadata": {
        "id": "fJJQaUlL5OCw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}